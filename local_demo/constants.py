import os
import hashlib

#############
# LongVA Demo Utils
#############

title_markdown = """
# [LongVA Multimodal Chat](https://lmm-lab.github.io/LongVA/)
"""

subtitle_markdown = """
### This is our research preview of LongVA, a multimodal model that is capable of accurately retrieving visual information from 2000 frames or more than 200K visual tokens.
"""

html_header = """
<style>
/* Existing Styles for Larger Screens */
.header-container {
  display: flex;
  justify-content: left;
  align-items: center;
  text-align: left;
  background: linear-gradient(45deg, rgba(195, 253, 245, 1), rgba(255, 0, 80, 0.3));
  border-radius: 10px;
  box-shadow: 0 8px 16px 0 rgba(0,0,0,0.1);
  padding: 10px 20px; /* Added padding */
}

.header-container img {
  max-width: 80px;
  height: auto;
  border-radius: 10px;
}

.header-container a {
  color: black; /* Ensure text color is always black */
  text-decoration: none;
}

/* Responsive adjustments for screens less than 768px wide */
@media (max-width: 768px) {
  .header-container {
    flex-direction: column;
    align-items: flex-start;
    padding: 10px 15px; /* Adjust padding for smaller screens */
  }

  .header-container img {
    max-width: 60px; /* Adjust image size for smaller screens */
  }

  .header-container h2, .header-container h5 {
  color: black; /* Ensure text color is always black */
  text-decoration: none;
    text-align: center; /* Center text on small screens */
    margin-top: 5px; /* Add top margin for better spacing after stacking */
  }

  .header-container h2 {
  color: black; /* Ensure text color is always black */
  text-decoration: none;
    font-size: 16px; /* Smaller font size for the title on mobile */
  }

  .header-container h5 {
  color: black; /* Ensure text color is always black */
  text-decoration: none;
    font-size: 12px; /* Smaller font size for the subtitle on mobile */
  }

  .header-container a {
  color: black; /* Ensure text color is always black */
  text-decoration: none;
  }
}
</style>

<div class="header-container">
  <a href="https://lmms-lab.github.io/posts/lmms-eval-0.2/" style="margin-right: 20px; text-decoration: none; display: flex; align-items: center;">
    <img src="https://i.postimg.cc/JhT7zPj3/assistant-logo.png" alt="LLaVA-NeXT">
  </a>
  <div>
    <h2><a href="https://lmms-lab.github.io/posts/lmms-eval-0.2/">Long Context Transfer from Language to Vision</a></h2>
    <h5><a href="https://github.com/EvolvingLMMs-Lab/LongVA">Github</a> | <a href="https://huggingface.co/collections/lmms-lab/longva-667538e09329dbc7ea498057">Huggingface</a> | <a href="https://lmms-lab.github.io/posts/longva/">Blog</a> | <a href="https://lmms-lab.github.io/posts/longva/">ArXiv Paper</a></h5>
    <h5>This is our research preview of LongVA, a multimodal model that is capable of accurately retrieving visual information from 2000 frames or more than 200K visual tokens.</h5>
  </div>
</div>
"""

block_css = """
#buttons button {
    min-width: min(120px,100%);
}
"""

tos_markdown = """
## Terms of use
By using this service, users are required to agree to the following terms:
The service is a research preview intended for non-commercial use only. It only provides limited safety measures and may generate offensive content. It must not be used for any illegal, harmful, violent, racist, or sexual purposes. The service may collect user dialogue data for future research.
Please click the "Flag" button if you get any inappropriate answer! We will collect those to keep improving our moderator.
For an optimal experience, please use desktop computers for this demo, as mobile devices may compromise its quality.
"""


learn_more_markdown = """
## License
The service is a research preview intended for non-commercial use only, subject to the model [License](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md) of LLaMA, [Terms of Use](https://openai.com/policies/terms-of-use) of the data generated by OpenAI, and [Privacy Practices](https://chrome.google.com/webstore/detail/sharegpt-share-your-chatg/daiacboceoaocpibfodeljbdfacokfjb) of ShareGPT. Please contact us if you find any potential violation.
"""

bibtext = """
## Citation
```
@misc{zhang2024longva,
    title={LongVA: Long Context Transfer from Language to Vision},
    url={https://lmms-lab.github.io/posts/longva/},
    author={Zhang, Peiyuan and Zhang, Kaichen and Li, Bo and Zeng, Guangtao and Yang, Jingkang and Zhang, Yuanhan and Li, Chunyuan and Liu, Ziwei},
    month={June},
    year={2024}
}
```
"""

PARENT_FOLDER = os.path.dirname(os.path.abspath(__file__))
################## BACKEND ##################
os.environ["GRADIO_EXAMPLES_CACHE"] = (
    f"{PARENT_FOLDER}/cache"
)
os.environ["GRADIO_TEMP_DIR"] = (
    f"{PARENT_FOLDER}/cache"
)

def generate_file_hash(file_path):
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()[:6]